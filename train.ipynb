{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from numba import jit\n",
    "SEED = 3407\n",
    "def seed_everything(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data():\n",
    "    train_set = pd.read_csv('train_data.csv',iterator=True)\n",
    "    train_set = train_set.get_chunk(size= 100000)\n",
    "    train_lab = pd.read_csv('train_labels.csv')\n",
    "    train_set = pd.merge(left=train_set,right=train_lab,on='customer_ID')\n",
    "    return train_set\n",
    "dataset = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def preprocess(dataset):\n",
    "    cus = dataset.groupby('customer_ID').count()\n",
    "    cus = cus[['target']]\n",
    "    dataset = pd.merge(left=dataset,right=cus,left_on='customer_ID',right_on=cus.index)\n",
    "    dataset = dataset[dataset['target_y'] == 13]\n",
    "    \n",
    "    dataset['D_87'].fillna(0,inplace=True)\n",
    "    cate = dataset[['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']]\n",
    "    encoder = OneHotEncoder()\n",
    "    oh = encoder.fit_transform(cate).toarray()\n",
    "    one_hot = [f'category{i}' for i in range(len(oh[0]))]\n",
    "    dataset = dataset.drop(columns=['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68'])\n",
    "    dataset[one_hot] = oh\n",
    "    dataset.fillna(method='pad',inplace=True)\n",
    "    dataset.fillna(value=1e-8,inplace=True)\n",
    "    dataset['S_2'] = pd.to_datetime(dataset['S_2'])\n",
    "    return dataset\n",
    "dataset = preprocess(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "split_time = datetime(year=2018,month=1,day=1)\n",
    "df_train = dataset[dataset['S_2']<split_time]\n",
    "df_valid = dataset[dataset['S_2']>=split_time]\n",
    "fea = [c for c in dataset.columns if c not in ['customer_ID','S_2','target_x','target_y','target_x']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\LenovoSoftstore\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8815479609419874"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logi_input = np.array(df_train[fea])\n",
    "logi_label = np.array(df_train['target_x'])\n",
    "valid_input = np.array(df_valid[fea])\n",
    "valid_label = np.array(df_valid['target_x'])\n",
    "\n",
    "logitstic = LogisticRegression(random_state=114514)\n",
    "logitstic.fit(logi_input,logi_label)\n",
    "logitstic.score(logi_input,logi_label)\n",
    "#logitstic.score(valid_input,valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_feature_label(data,seq_len,batchisze=1741):\n",
    "    num_sample = int(len(data)/seq_len)\n",
    "    \n",
    "    row = np.array(range(len(data))).reshape([num_sample,seq_len])[:,-1]\n",
    "    label = np.array(data['target_x'])\n",
    "    label = label[row]\n",
    "    feature = np.array(data[fea])\n",
    "\n",
    "    label = tf.constant(label,shape=[num_sample,1,1])\n",
    "    feature = tf.constant(feature,shape=[num_sample,seq_len,len(fea)])\n",
    "    return feature,label\n",
    "\n",
    "tr_feature,tr_label = split_feature_label(df_train,10)\n",
    "va_feature,va_label = split_feature_label(df_valid,3)\n",
    "feature,label = split_feature_label(dataset,13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 0.6164 - binary_accuracy: 0.7688 - val_loss: 0.4598 - val_binary_accuracy: 0.7598\n",
      "Epoch 2/80\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.3480 - binary_accuracy: 0.8363 - val_loss: 0.2684 - val_binary_accuracy: 0.8828\n",
      "Epoch 3/80\n",
      "20/20 [==============================] - 0s 21ms/step - loss: 0.2634 - binary_accuracy: 0.8863 - val_loss: 0.2426 - val_binary_accuracy: 0.8914\n",
      "Epoch 4/80\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 0.2375 - binary_accuracy: 0.8927 - val_loss: 0.2403 - val_binary_accuracy: 0.8919\n",
      "Epoch 5/80\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.2383 - binary_accuracy: 0.8952 - val_loss: 0.2284 - val_binary_accuracy: 0.8957\n",
      "Epoch 6/80\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.2321 - binary_accuracy: 0.8954 - val_loss: 0.2272 - val_binary_accuracy: 0.9010\n",
      "Epoch 7/80\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.2235 - binary_accuracy: 0.8982 - val_loss: 0.2188 - val_binary_accuracy: 0.8990\n",
      "Epoch 8/80\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.2182 - binary_accuracy: 0.9019 - val_loss: 0.2169 - val_binary_accuracy: 0.9024\n",
      "Epoch 9/80\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.2165 - binary_accuracy: 0.9032 - val_loss: 0.2176 - val_binary_accuracy: 0.9029\n",
      "Epoch 10/80\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 0.2140 - binary_accuracy: 0.9050 - val_loss: 0.2163 - val_binary_accuracy: 0.8976\n",
      "Epoch 11/80\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.2129 - binary_accuracy: 0.9042 - val_loss: 0.2164 - val_binary_accuracy: 0.9005\n",
      "Epoch 12/80\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.2078 - binary_accuracy: 0.9087 - val_loss: 0.2156 - val_binary_accuracy: 0.9067\n",
      "Epoch 13/80\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.2097 - binary_accuracy: 0.9032 - val_loss: 0.2165 - val_binary_accuracy: 0.9048\n",
      "Epoch 14/80\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.2033 - binary_accuracy: 0.9099 - val_loss: 0.2211 - val_binary_accuracy: 0.9033\n",
      "Epoch 15/80\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.2066 - binary_accuracy: 0.9073 - val_loss: 0.2261 - val_binary_accuracy: 0.9038\n",
      "Epoch 16/80\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.2000 - binary_accuracy: 0.9114 - val_loss: 0.2174 - val_binary_accuracy: 0.9053\n",
      "Epoch 17/80\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.1958 - binary_accuracy: 0.9130 - val_loss: 0.2174 - val_binary_accuracy: 0.9038\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import tensorboard\n",
    "OUT_STEPS = 4\n",
    "num_features =len(fea)\n",
    "multi_dense_model = tf.keras.Sequential([\n",
    "    # 提取最后一时间步的数据\n",
    "\n",
    "    # Shape [batch, time, features] => [batch, 1, features]\n",
    "    tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n",
    "    # Shape => [batch, 1, dense_units]\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    #tf.keras.layers.Dense(365, activation='relu'),\n",
    "    tf.keras.layers.Dense(3*7, activation='relu'),\n",
    "    # Shape => [batch, out_steps*features]\n",
    "    tf.keras.layers.Dense(4,kernel_initializer=tf.initializers.zeros(), activation='sigmoid'),\n",
    "    # Shape => [batch, out_steps, features]\n",
    "    tf.keras.layers.Reshape([OUT_STEPS, 1])\n",
    "])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=5,\n",
    "                                                    mode='min')\n",
    "\n",
    "log_dir = \"logs/mlp/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "multi_dense_model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False,label_smoothing=0.0,\n",
    "                axis=-1,name='binary_crossentropy'),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[tf.keras.metrics.BinaryAccuracy(name='binary_accuracy', dtype=None, threshold=0.5)\n",
    "])\n",
    "\n",
    "history = multi_dense_model.fit(\n",
    "    x=feature, y = label, \n",
    "    batch_size=256, \n",
    "    epochs=80, \n",
    "    verbose=1, \n",
    "    callbacks=[early_stopping,tensorboard_callback], \n",
    "    #valid_input = va_feature,valid_label = va_label,\n",
    "    validation_split=0.3,  \n",
    "    shuffle=True, \n",
    "    class_weight=None, \n",
    "    sample_weight=None, \n",
    "    initial_epoch=0, \n",
    "    steps_per_epoch=None, \n",
    "    validation_steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.4436 - binary_accuracy: 0.7688 - val_loss: 0.3370 - val_binary_accuracy: 0.7584\n",
      "Epoch 2/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.3130 - binary_accuracy: 0.7864 - val_loss: 0.3094 - val_binary_accuracy: 0.8057\n",
      "Epoch 3/100\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.2972 - binary_accuracy: 0.8275 - val_loss: 0.2997 - val_binary_accuracy: 0.8378\n",
      "Epoch 4/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.2878 - binary_accuracy: 0.8508 - val_loss: 0.2948 - val_binary_accuracy: 0.8455\n",
      "Epoch 5/100\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.2818 - binary_accuracy: 0.8650 - val_loss: 0.2889 - val_binary_accuracy: 0.8718\n",
      "Epoch 6/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.2770 - binary_accuracy: 0.8818 - val_loss: 0.2890 - val_binary_accuracy: 0.8880\n",
      "Epoch 7/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.2704 - binary_accuracy: 0.8867 - val_loss: 0.2821 - val_binary_accuracy: 0.8818\n",
      "Epoch 8/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.2651 - binary_accuracy: 0.8874 - val_loss: 0.2791 - val_binary_accuracy: 0.8876\n",
      "Epoch 9/100\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.2610 - binary_accuracy: 0.8960 - val_loss: 0.2803 - val_binary_accuracy: 0.8880\n",
      "Epoch 10/100\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.2567 - binary_accuracy: 0.8968 - val_loss: 0.2747 - val_binary_accuracy: 0.8990\n",
      "Epoch 11/100\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.2535 - binary_accuracy: 0.9019 - val_loss: 0.2715 - val_binary_accuracy: 0.8986\n",
      "Epoch 12/100\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.2493 - binary_accuracy: 0.9025 - val_loss: 0.2701 - val_binary_accuracy: 0.8986\n",
      "Epoch 13/100\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.2482 - binary_accuracy: 0.9007 - val_loss: 0.2686 - val_binary_accuracy: 0.8967\n",
      "Epoch 14/100\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.2425 - binary_accuracy: 0.9060 - val_loss: 0.2682 - val_binary_accuracy: 0.8967\n",
      "Epoch 15/100\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.2431 - binary_accuracy: 0.9038 - val_loss: 0.2661 - val_binary_accuracy: 0.9014\n",
      "Epoch 16/100\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.2371 - binary_accuracy: 0.9046 - val_loss: 0.2636 - val_binary_accuracy: 0.9014\n",
      "Epoch 17/100\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.2353 - binary_accuracy: 0.9064 - val_loss: 0.2653 - val_binary_accuracy: 0.9000\n",
      "Epoch 18/100\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.2330 - binary_accuracy: 0.9071 - val_loss: 0.2641 - val_binary_accuracy: 0.8986\n",
      "Epoch 19/100\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.2287 - binary_accuracy: 0.9081 - val_loss: 0.2630 - val_binary_accuracy: 0.9033\n",
      "Epoch 20/100\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.2250 - binary_accuracy: 0.9124 - val_loss: 0.2625 - val_binary_accuracy: 0.9019\n",
      "Epoch 21/100\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.2226 - binary_accuracy: 0.9132 - val_loss: 0.2625 - val_binary_accuracy: 0.9010\n",
      "Epoch 22/100\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.2195 - binary_accuracy: 0.9136 - val_loss: 0.2616 - val_binary_accuracy: 0.9005\n",
      "Epoch 23/100\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.2181 - binary_accuracy: 0.9144 - val_loss: 0.2590 - val_binary_accuracy: 0.9043\n",
      "Epoch 24/100\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.2143 - binary_accuracy: 0.9151 - val_loss: 0.2593 - val_binary_accuracy: 0.9053\n",
      "Epoch 25/100\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.2116 - binary_accuracy: 0.9165 - val_loss: 0.2583 - val_binary_accuracy: 0.9067\n",
      "Epoch 26/100\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.2098 - binary_accuracy: 0.9175 - val_loss: 0.2621 - val_binary_accuracy: 0.9038\n",
      "Epoch 27/100\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.2069 - binary_accuracy: 0.9200 - val_loss: 0.2547 - val_binary_accuracy: 0.9005\n",
      "Epoch 28/100\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.2034 - binary_accuracy: 0.9220 - val_loss: 0.2557 - val_binary_accuracy: 0.9033\n",
      "Epoch 29/100\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.2012 - binary_accuracy: 0.9235 - val_loss: 0.2530 - val_binary_accuracy: 0.8981\n",
      "Epoch 30/100\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.1975 - binary_accuracy: 0.9278 - val_loss: 0.2586 - val_binary_accuracy: 0.9067\n",
      "Epoch 31/100\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.1955 - binary_accuracy: 0.9257 - val_loss: 0.2571 - val_binary_accuracy: 0.9043\n",
      "Epoch 32/100\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.1917 - binary_accuracy: 0.9296 - val_loss: 0.2536 - val_binary_accuracy: 0.9024\n",
      "Epoch 33/100\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.1881 - binary_accuracy: 0.9300 - val_loss: 0.2533 - val_binary_accuracy: 0.9019\n"
     ]
    }
   ],
   "source": [
    "CONV_WIDTH = 6\n",
    "OUT_STEPS = 4\n",
    "num_features = feature.shape[-1]\n",
    "multi_conv_model = tf.keras.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, CONV_WIDTH, features]\n",
    "    tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :]),\n",
    "    # Shape => [batch, 1, conv_units]\n",
    "    tf.keras.layers.Conv1D(256, activation='sigmoid', kernel_size=(CONV_WIDTH)),\n",
    "\n",
    "    # Shape => [batch, 1,  out_steps*features]\n",
    "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
    "                          kernel_initializer=tf.initializers.zeros(),activation = 'sigmoid'),\n",
    "    # Shape => [batch, out_steps, features]\n",
    "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
    "])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=4, restore_best_weights=True,\n",
    "                                                    mode='min')\n",
    "\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: 1e-8 * 10**(epoch / 20))\n",
    "\n",
    "log_dir = \"logs/CNN/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "multi_conv_model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False,label_smoothing=0.0,\n",
    "                axis=-1,name='binary_crossentropy'),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[tf.keras.metrics.BinaryAccuracy(name='binary_accuracy', dtype=None, threshold=0.5)\n",
    "])\n",
    "\n",
    "history = multi_conv_model.fit(\n",
    "    x=feature, y = label, \n",
    "    batch_size=128, \n",
    "    epochs=100, \n",
    "    verbose=1, \n",
    "    callbacks=[early_stopping,tensorboard_callback], \n",
    "    validation_split=0.3,  \n",
    "    shuffle=True, \n",
    "    class_weight=None, \n",
    "    sample_weight=None, \n",
    "    initial_epoch=0, \n",
    "    steps_per_epoch=None, \n",
    "    validation_steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "244/244 [==============================] - 9s 21ms/step - loss: 0.3530 - binary_accuracy: 0.8539 - val_loss: 0.2774 - val_binary_accuracy: 0.8866\n",
      "Epoch 2/100\n",
      "244/244 [==============================] - 3s 12ms/step - loss: 0.2571 - binary_accuracy: 0.8894 - val_loss: 0.2508 - val_binary_accuracy: 0.8927\n",
      "Epoch 3/100\n",
      "244/244 [==============================] - 3s 11ms/step - loss: 0.2329 - binary_accuracy: 0.8993 - val_loss: 0.2396 - val_binary_accuracy: 0.8997\n",
      "Epoch 4/100\n",
      "244/244 [==============================] - 3s 11ms/step - loss: 0.2195 - binary_accuracy: 0.9031 - val_loss: 0.2236 - val_binary_accuracy: 0.9049\n",
      "Epoch 5/100\n",
      "244/244 [==============================] - 3s 11ms/step - loss: 0.2105 - binary_accuracy: 0.9094 - val_loss: 0.2500 - val_binary_accuracy: 0.8898\n",
      "Epoch 6/100\n",
      "244/244 [==============================] - 3s 11ms/step - loss: 0.2001 - binary_accuracy: 0.9155 - val_loss: 0.2360 - val_binary_accuracy: 0.8922\n",
      "Epoch 7/100\n",
      "244/244 [==============================] - 3s 11ms/step - loss: 0.1897 - binary_accuracy: 0.9188 - val_loss: 0.2213 - val_binary_accuracy: 0.9073\n",
      "Epoch 8/100\n",
      "244/244 [==============================] - 3s 11ms/step - loss: 0.1773 - binary_accuracy: 0.9224 - val_loss: 0.2271 - val_binary_accuracy: 0.9021\n",
      "Epoch 9/100\n",
      "244/244 [==============================] - 3s 11ms/step - loss: 0.1662 - binary_accuracy: 0.9270 - val_loss: 0.2400 - val_binary_accuracy: 0.8984\n",
      "Epoch 10/100\n",
      "244/244 [==============================] - 3s 11ms/step - loss: 0.1557 - binary_accuracy: 0.9310 - val_loss: 0.2516 - val_binary_accuracy: 0.8960\n",
      "Epoch 11/100\n",
      "244/244 [==============================] - 3s 12ms/step - loss: 0.1485 - binary_accuracy: 0.9364 - val_loss: 0.2504 - val_binary_accuracy: 0.9008\n",
      "Epoch 12/100\n",
      "244/244 [==============================] - 3s 11ms/step - loss: 0.1401 - binary_accuracy: 0.9411 - val_loss: 0.2712 - val_binary_accuracy: 0.9022\n"
     ]
    }
   ],
   "source": [
    "lstm_model = tf.keras.models.Sequential([\n",
    "  #tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),input_shape=[None]),\n",
    "  tf.keras.layers.LSTM(\n",
    "    units = 21,\n",
    "    activation=\"tanh\",\n",
    "    recurrent_activation=\"sigmoid\",return_sequences= True),\n",
    "  tf.keras.layers.LSTM(\n",
    "    units = 7,\n",
    "    activation=\"tanh\",\n",
    "    recurrent_activation=\"sigmoid\"),\n",
    "  tf.keras.layers.Dense(3,activation=\"sigmoid\"),\n",
    "  tf.keras.layers.Lambda(lambda x: x * 1)\n",
    "])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=5, restore_best_weights=True,\n",
    "                                                    mode='min')\n",
    "\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: 0.1 * 10**(-epoch / 20))\n",
    "\n",
    "log_dir = \"logs/LSTM/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "lstm_model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False,label_smoothing=0.0,\n",
    "                axis=-1,name='binary_crossentropy'),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[tf.keras.metrics.BinaryAccuracy(name='binary_accuracy', dtype=None, threshold=0.5)\n",
    "])\n",
    "history = lstm_model.fit(\n",
    "    x=feature, y = label, \n",
    "    batch_size=20, \n",
    "    epochs=100, \n",
    "    verbose=1, \n",
    "    callbacks=[early_stopping,tensorboard_callback], \n",
    "    validation_split=0.3,  \n",
    "    shuffle=True, \n",
    "    class_weight=None, \n",
    "    sample_weight=None, \n",
    "    initial_epoch=0, \n",
    "    steps_per_epoch=None, \n",
    "    validation_steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "77/77 [==============================] - 7s 52ms/step - loss: 0.4246 - binary_accuracy: 0.7899 - val_loss: 0.3192 - val_binary_accuracy: 0.8578\n",
      "Epoch 2/200\n",
      "77/77 [==============================] - 3s 45ms/step - loss: 0.3321 - binary_accuracy: 0.8707 - val_loss: 0.3107 - val_binary_accuracy: 0.8894\n",
      "Epoch 3/200\n",
      "77/77 [==============================] - 3s 43ms/step - loss: 0.2898 - binary_accuracy: 0.8879 - val_loss: 0.2688 - val_binary_accuracy: 0.8950\n",
      "Epoch 4/200\n",
      "77/77 [==============================] - 3s 43ms/step - loss: 0.2831 - binary_accuracy: 0.8847 - val_loss: 0.2901 - val_binary_accuracy: 0.8648\n",
      "Epoch 5/200\n",
      "77/77 [==============================] - 3s 43ms/step - loss: 0.2670 - binary_accuracy: 0.8894 - val_loss: 0.2656 - val_binary_accuracy: 0.8939\n",
      "Epoch 6/200\n",
      "77/77 [==============================] - 3s 42ms/step - loss: 0.2684 - binary_accuracy: 0.8943 - val_loss: 0.2479 - val_binary_accuracy: 0.8982\n",
      "Epoch 7/200\n",
      "77/77 [==============================] - 3s 42ms/step - loss: 0.2504 - binary_accuracy: 0.8955 - val_loss: 0.3072 - val_binary_accuracy: 0.8969\n",
      "Epoch 8/200\n",
      "77/77 [==============================] - 3s 42ms/step - loss: 0.2449 - binary_accuracy: 0.8970 - val_loss: 0.2760 - val_binary_accuracy: 0.9016\n",
      "Epoch 9/200\n",
      "77/77 [==============================] - 3s 42ms/step - loss: 0.2391 - binary_accuracy: 0.9040 - val_loss: 0.3141 - val_binary_accuracy: 0.9004\n",
      "Epoch 10/200\n",
      "77/77 [==============================] - 3s 43ms/step - loss: 0.2219 - binary_accuracy: 0.9137 - val_loss: 0.2995 - val_binary_accuracy: 0.8945\n",
      "Epoch 11/200\n",
      "77/77 [==============================] - 3s 43ms/step - loss: 0.2557 - binary_accuracy: 0.9046 - val_loss: 0.2741 - val_binary_accuracy: 0.8943\n"
     ]
    }
   ],
   "source": [
    "import Tfm\n",
    "\n",
    "tfm_model = Tfm.tsf_model(\n",
    "    input_shape = feature.shape[1:],\n",
    "    output_len = 4,\n",
    "    head_size=64,\n",
    "    num_heads=8,\n",
    "    ff_dim=16,\n",
    "    num_transformer_blocks=4,\n",
    "    mlp_units=[128],\n",
    "    #mlp_dropout=4,\n",
    "    #dropout=2,\n",
    ")\n",
    "\n",
    "log_dir = \"logs/Transformer/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "tfm_model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False,label_smoothing=0.0,\n",
    "                axis=-1,name='binary_crossentropy'),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[tf.keras.metrics.BinaryAccuracy(name='binary_accuracy', dtype=None, threshold=0.5)\n",
    "])\n",
    "\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=5,restore_best_weights=True,\n",
    "                                                    mode='min'),tensorboard_callback]\n",
    "\n",
    "history = tfm_model.fit(\n",
    "    x = feature,\n",
    "    y = label,\n",
    "    validation_split=0.3,\n",
    "    epochs=200,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "230b3ff13fbf17182562d98b6b92d0993293f138d9d821fa36058128ba3119c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
